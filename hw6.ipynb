{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, RegexpTokenizer, download\n",
    "\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "from numpy import array, savetxt\n",
    "\n",
    "from csv import writer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Sentiment = 0|1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dict( x: str, d: dict, s: Sentiment ):\n",
    "    d[x][s] = d.get(x)[s]+1\n",
    "\n",
    "def init_dict( x: str, d: dict ):\n",
    "    d[x] = {0: 0, 1: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./files/yelp_train.csv\", names=['text', 'sentiment'])\n",
    "c_prior = train_df['sentiment'].value_counts()\n",
    "p_prior = c_prior/(c_prior[0] + c_prior[1])\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "train_df['tok_text'] = train_df.apply(lambda row: tokenizer.tokenize(row['text'].lower()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prior = p_prior.rename({0: 'negative', 1: 'positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prior = list(zip(p_prior.index, p_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_train_vocab(df):\n",
    "    wc_pos = 0\n",
    "    wc_neg = 0\n",
    "    df_neg = df[df['sentiment'] == 0]\n",
    "    df_pos = df[df['sentiment'] == 1]\n",
    "    vocab = {}\n",
    "    for p in df['tok_text']:\n",
    "        for q in p:\n",
    "            init_dict(q, vocab)\n",
    "    for p in df_neg['tok_text']:\n",
    "        for q in p:\n",
    "            insert_dict(q, vocab, 0)\n",
    "            wc_neg += 1\n",
    "    for p in df_pos['tok_text']:\n",
    "        for q in p:\n",
    "            insert_dict(q, vocab, 1)\n",
    "            wc_pos += 1\n",
    "    return vocab, wc_pos, wc_neg\n",
    "    \n",
    "vocab, wc_pos, wc_neg = mk_train_vocab(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "pos_array = []\n",
    "neg_array = []\n",
    "for word in vocab:\n",
    "    pos_array.append([word, 'positive', (vocab.get(word)[0]+1)/(wc_pos+len(vocab))])\n",
    "    neg_array.append([word, 'negative', (vocab.get(word)[1]+1)/(wc_neg+len(vocab))])\n",
    "maxp = ['', '', 0]\n",
    "minp = ['', '', 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'negative', 0.026595744680851064]\n",
      "['crust', 'negative', 0.0026595744680851063]\n"
     ]
    }
   ],
   "source": [
    "for e in neg_array:\n",
    "    if e[2] > maxp[2]:\n",
    "        maxp = e\n",
    "    if e[2] < minp[2]:\n",
    "        minp = e\n",
    "print(maxp)\n",
    "print(minp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('negative', 0.5), ('positive', 0.5)]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_prior = list(map(lambda x: [x[0], log(x[1])], p_prior))\n",
    "logneg_array = list(map(lambda x: [x[0], x[1], log(x[2])],neg_array))\n",
    "logpos_array = list(map(lambda x: [x[0], x[1], log(x[2])],pos_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crust', 'negative', -6.263398262591624]\n",
      "['the', 'negative', -3.960813169597578]\n"
     ]
    }
   ],
   "source": [
    "maxp = ['', '', 100]\n",
    "minp = ['', '', -100]\n",
    "for e in logneg_array:\n",
    "    if e[2] < maxp[2]:\n",
    "        maxp = e\n",
    "    if e[2] > minp[2]:\n",
    "        minp = e\n",
    "print(maxp)\n",
    "print(minp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove, path\n",
    "\n",
    "filename = 'c_model.csv'\n",
    "\n",
    "if path.exists(filename):\n",
    "    remove(filename)\n",
    "\n",
    "with open(filename, 'a') as f:\n",
    "    wr = writer(f, delimiter=',')\n",
    "    f.write('PP\\n')\n",
    "    wr.writerows(log_p_prior)\n",
    "    f.write('\\nLP\\n')\n",
    "    wr.writerows(logneg_array)\n",
    "    wr.writerows(logpos_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = pd.read_csv(filename, skiprows=0, nrows=2)\n",
    "c_df = pd.read_csv(filename, skiprows=4)\n",
    "p_df = p_df.rename(index={0: 'negative', 1: 'positive'}, columns={'PP': 'probability'})\n",
    "c_df = c_df.rename(columns={'LP': 'probability'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.570251082031678"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.loc[('wow', 'negative'), 'LP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df.loc['negative', 'probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Server did a great job handling our large rowd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Would come back again if I had a sushi craving...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He deserves 5 stars.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My boyfriend and I came here for the first tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They have great dinners.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Not my thing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you are reading this please don't go there.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tonight I had the Elk Filet special...and it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We ordered some old classics and some new dish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A FLY was in my apple juice.. A FLY!!!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Server did a great job handling our large rowd...          1\n",
       "1  Would come back again if I had a sushi craving...          1\n",
       "2                               He deserves 5 stars.          1\n",
       "3  My boyfriend and I came here for the first tim...          1\n",
       "4                           They have great dinners.          1\n",
       "5                                      Not my thing.          0\n",
       "6     If you are reading this please don't go there.          0\n",
       "7  Tonight I had the Elk Filet special...and it s...          0\n",
       "8  We ordered some old classics and some new dish...          0\n",
       "9        A FLY was in my apple juice.. A FLY!!!!!!!!          0"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./files/yelp_test.csv\", names=['text', 'sentiment'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl_probability( vocab: dict, cl: str, p_model: pd.DataFrame, c_model: pd.DataFrame ):\n",
    "    prob = [p_model.loc[cl, 'probability']]\n",
    "    for word in vocab:\n",
    "        prob.append(c_model.loc[word, cl, 'probability'])\n",
    "    return sum(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify( text: str, p_model: pd.DataFrame, c_model: pd.DataFrame ):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    t_arr = tokenizer.tokenize(text.lower())\n",
    "    vocab = {}\n",
    "    for word in t_arr:\n",
    "        if word in vocab.keys():\n",
    "            vocab[word] = vocab.get(word) + 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "\n",
    "    p_neg = cl_probability( vocab, 'negative', p_model, c_model)\n",
    "    p_pos = cl_probability( vocab, 'positive', p_model, c_model)\n",
    "    return 'positive' if p_neg < p_pos else 'negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [381], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [378], line 11\u001b[0m, in \u001b[0;36mclassify\u001b[0;34m(text, p_model, c_model)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         vocab[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 11\u001b[0m p_neg \u001b[38;5;241m=\u001b[39m \u001b[43mcl_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m p_pos \u001b[38;5;241m=\u001b[39m cl_probability( vocab, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m, p_model, c_model)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p_neg \u001b[38;5;241m<\u001b[39m p_pos \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn [377], line 4\u001b[0m, in \u001b[0;36mcl_probability\u001b[0;34m(vocab, cl, p_model, c_model)\u001b[0m\n\u001b[1;32m      2\u001b[0m prob \u001b[38;5;241m=\u001b[39m [p_model\u001b[38;5;241m.\u001b[39mloc[cl, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m vocab:\n\u001b[0;32m----> 4\u001b[0m     prob\u001b[38;5;241m.\u001b[39mappend(\u001b[43mc_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprobability\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(prob)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/csc620/lib/python3.10/site-packages/pandas/core/indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/csc620/lib/python3.10/site-packages/pandas/core/indexing.py:1143\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[1;32m   1142\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tuple_indexer(tup)\n\u001b[1;32m   1145\u001b[0m \u001b[39m# ugly hack for GH #836\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/csc620/lib/python3.10/site-packages/pandas/core/indexing.py:765\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_tuple_indexer\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mtuple\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m:\n\u001b[1;32m    762\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39m    Check the key for valid keys across my indexer.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 765\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_key_length(key)\n\u001b[1;32m    766\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(key)\n\u001b[1;32m    767\u001b[0m     \u001b[39mfor\u001b[39;00m i, k \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/csc620/lib/python3.10/site-packages/pandas/core/indexing.py:812\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_key_length\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[39mraise\u001b[39;00m IndexingError(_one_ellipsis_message)\n\u001b[1;32m    811\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key_length(key)\n\u001b[0;32m--> 812\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mToo many indexers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    813\u001b[0m \u001b[39mreturn\u001b[39;00m key\n",
      "\u001b[0;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "classify(test_df.loc[0, 'text'], p_df, c_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('csc620')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a71d39d660cde086a1906713d7782789105334eb77ec37352255bdee7f037f90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
