{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 620 - HW 6 - Text Classification Using Naïve Bayes\n",
    "### Mark Kim\n",
    "\n",
    "This assignment involves the implementation of a text classifier using a Naïve\n",
    "Bayes method.  Laplace smoothing was applied to the data for this program.  The\n",
    "resulting MLE is as follows:\n",
    "$$ \\hat{P}(w|c) = \\frac{\\operatorname{count}(w,c) + 1}{\\operatorname{count}(c) + \\lvert\n",
    "V \\rvert}. $$\n",
    "Once all the conditional probabilities are calculated, class labels are\n",
    "determined by finding the class with the highest probability, which can be\n",
    "generalized by:\n",
    "$$ C_{NB} = \\underset{c\\in C}{\\operatorname*{argmax}}\\ P(c_j)\\prod_{x\\in X}\n",
    "P(x|c) $$\n",
    "\n",
    "This project consists of a data set of 50 restaurant reviews pulled from Yelp!\n",
    "40 reviews were used for the training set and 10 were used for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, RegexpTokenizer, download\n",
    "\n",
    "from numpy import array, savetxt\n",
    "\n",
    "from csv import writer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Literal integer sum type declaration\n",
    "Sentiment = 0|1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions\n",
    "\n",
    "These functions are for dictionary initialization and data insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dict( x: str, d: dict, s: Sentiment ):\n",
    "    d[x][s] = d.get(x)[s]+1\n",
    "\n",
    "def init_dict( x: str, d: dict ):\n",
    "    d[x] = {0: 0, 1: 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Probability Function\n",
    "\n",
    "This function calculates the conditional probability that a text/document\n",
    "belongs to a particular class.  To avoid numerical underflow due to the\n",
    "diminishing nature of multiplying fractions, this calculation is formulated to\n",
    "utilize log-likelihoods rather than probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl_probability( vocab: dict, cl: str, p_model: pd.DataFrame, c_model: pd.DataFrame ):\n",
    "    prob = [p_model.loc[cl, 'probability']]\n",
    "    for word in vocab:\n",
    "        prob.append(c_model.loc[(word, cl), 'probability'] * vocab[word])\n",
    "    return sum(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Function\n",
    "\n",
    "This function receives a text string, a prior probability table, and a\n",
    "conditional probability table.  It then produces a vocabulary of known words in\n",
    "the text string minus any words that are not contained in our models.  Using\n",
    "this vocabulary, it utilizes the `cl_probability()` function to determine the\n",
    "log-likelihood of the class being either negative or positive and returns the\n",
    "value associated with that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify( text: str, p_model: pd.DataFrame, c_model: pd.DataFrame ):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    t_arr = tokenizer.tokenize(text.lower())\n",
    "    cni_df = c_model.reset_index()\n",
    "    vocab = {}\n",
    "    for word in t_arr:\n",
    "        if word not in cni_df.loc[:, 'level_0'].values:\n",
    "            continue\n",
    "        if word in vocab.keys():\n",
    "            vocab[word] = vocab.get(word) + 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "\n",
    "    p_neg = cl_probability( vocab, 'negative', p_model, c_model)\n",
    "    p_pos = cl_probability( vocab, 'positive', p_model, c_model)\n",
    "    return 1 if p_neg < p_pos else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Vocabulary Function\n",
    "\n",
    "This function takes in a dataframe of labeled data and creates a vocabulary from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_train_vocab(df):\n",
    "    wc_pos = 0\n",
    "    wc_neg = 0\n",
    "    df_neg = df[df['sentiment'] == 0]\n",
    "    df_pos = df[df['sentiment'] == 1]\n",
    "    vocab = {}\n",
    "    for p in df['tok_text']:\n",
    "        for q in p:\n",
    "            init_dict(q, vocab)\n",
    "    for p in df_neg['tok_text']:\n",
    "        for q in p:\n",
    "            insert_dict(q, vocab, 0)\n",
    "            wc_neg += 1\n",
    "    for p in df_pos['tok_text']:\n",
    "        for q in p:\n",
    "            insert_dict(q, vocab, 1)\n",
    "            wc_pos += 1\n",
    "    return vocab, wc_pos, wc_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Training Data\n",
    "\n",
    "Here, we read in the training data and calculate and store the counts of words\n",
    "associated with positive and negative reviews.  Next, the conditional\n",
    "probabilities are calculated and some preprocessing is done to prepare the\n",
    "training data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\", names=['text', 'sentiment'])\n",
    "c_prior = train_df['sentiment'].value_counts()\n",
    "p_prior = c_prior/(c_prior[0] + c_prior[1])\n",
    "p_prior = p_prior.rename({0: 'negative', 1: 'positive'})\n",
    "p_prior = list(zip(p_prior.index, p_prior))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "train_df['tok_text'] = train_df.apply(lambda row: tokenizer.tokenize(row['text'].lower()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make vocabulary from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, wc_pos, wc_neg = mk_train_vocab(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Arrays for Positive and Negative Reviews\n",
    "\n",
    "This produces two arrays of data that contains a vocabulary of the training\n",
    "data along with the probabilities that each word occurs within the data set.\n",
    "Laplace smoothing has been applied to the resulting probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "pos_array = []\n",
    "neg_array = []\n",
    "for word in vocab:\n",
    "    pos_array.append([word, 'positive', (vocab.get(word)[1]+1)/(wc_pos+len(vocab))])\n",
    "    neg_array.append([word, 'negative', (vocab.get(word)[0]+1)/(wc_neg+len(vocab))])\n",
    "maxp = ['', '', 0]\n",
    "minp = ['', '', 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-likelihood\n",
    "\n",
    "Because of the possibility of underflow from multiplying fractions, I took the\n",
    "logarithm of each probability.  Once applied, the logarithm converts the next\n",
    "calculations to addition (and multiplication when multiple instances of a word\n",
    "is found)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_prior = list(map(lambda x: [x[0], log(x[1])], p_prior))\n",
    "logneg_array = list(map(lambda x: [x[0], x[1], log(x[2])],neg_array))\n",
    "logpos_array = list(map(lambda x: [x[0], x[1], log(x[2])],pos_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Model to CSV\n",
    "\n",
    "As specified, the model is written to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove, path\n",
    "\n",
    "filename = './model.csv'\n",
    "\n",
    "if path.exists(filename):\n",
    "    remove(filename)\n",
    "\n",
    "with open(filename, 'a') as f:\n",
    "    wr = writer(f, delimiter=',')\n",
    "    f.write('PP\\n')\n",
    "    wr.writerows(log_p_prior)\n",
    "    f.write('\\nLP\\n')\n",
    "    wr.writerows(logneg_array)\n",
    "    wr.writerows(logpos_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Trained Model\n",
    "\n",
    "To test a model, the trained model file is read in and pre-processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = pd.read_csv(filename, skiprows=0, nrows=2)\n",
    "c_df = pd.read_csv(filename, skiprows=4)\n",
    "p_df = p_df.rename(index={0: 'negative', 1: 'positive'}, columns={'PP': 'probability'})\n",
    "c_df = c_df.rename(columns={'LP': 'probability'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Test Data\n",
    "\n",
    "We read in the test data and predict classifications and enter them into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./test.csv\", names=['text', 'sentiment'])\n",
    "\n",
    "predict = []\n",
    "for text in test_df['text']:\n",
    "    predict.append(classify( text, p_df, c_df ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Processing\n",
    "\n",
    "Enter results into the existing test dataframe and apply label changes accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prediction'] = predict\n",
    "test_df['sentiment'] = test_df.apply(lambda row: 'positive' if row['sentiment'] == 1 else 'negative', axis=1)\n",
    "test_df['prediction'] = test_df.apply(lambda row: 'positive' if row['prediction'] == 1 else 'negative', axis=1)\n",
    "test_df = test_df.rename(columns={'sentiment': 'actual'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Results to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Server did a great job handling our large rowd...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Would come back again if I had a sushi craving...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He deserves 5 stars.</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My boyfriend and I came here for the first tim...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They have great dinners.</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Not my thing.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you are reading this please don't go there.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tonight I had the Elk Filet special...and it s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We ordered some old classics and some new dish...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A FLY was in my apple juice.. A FLY!!!!!!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    actual prediction\n",
       "0  Server did a great job handling our large rowd...  positive   positive\n",
       "1  Would come back again if I had a sushi craving...  positive   negative\n",
       "2                               He deserves 5 stars.  positive   positive\n",
       "3  My boyfriend and I came here for the first tim...  positive   positive\n",
       "4                           They have great dinners.  positive   positive\n",
       "5                                      Not my thing.  negative   negative\n",
       "6     If you are reading this please don't go there.  negative   negative\n",
       "7  Tonight I had the Elk Filet special...and it s...  negative   negative\n",
       "8  We ordered some old classics and some new dish...  negative   positive\n",
       "9        A FLY was in my apple juice.. A FLY!!!!!!!!  negative   negative"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.to_csv('./test_predictions.csv')\n",
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a71d39d660cde086a1906713d7782789105334eb77ec37352255bdee7f037f90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
