{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "class Autocorrect:\n",
    "    def __init__(self, corpus):\n",
    "        self._words = corpus\n",
    "        self._word_freq = self.get_word_freq(corpus)\n",
    "    \n",
    "    def get_word_freq(self, corpus) -> dict:\n",
    "        wordcount = len(corpus)\n",
    "        freq_dict = {}\n",
    "        for word in corpus:\n",
    "            if word in freq_dict.keys():\n",
    "                count = freq_dict.get(word)[\"cnt\"] + 1\n",
    "                freq_dict[word] = { \"cnt\": count }\n",
    "            else:\n",
    "                freq_dict[word] = { \"cnt\": 1 }\n",
    "        for key in freq_dict:\n",
    "            freq_dict[key][\"rel\"] = freq_dict[key][\"cnt\"]/wordcount\n",
    "        return freq_dict\n",
    "\n",
    "    def checkWord(self, string) -> list:\n",
    "        if string in self._word_freq:\n",
    "            return [(0, string, self._word_freq[string][\"rel\"])]\n",
    "        match = []\n",
    "        for key in self._word_freq:\n",
    "            dist = edit_distance(string, key, substitution_cost=2)\n",
    "            match.append((dist, key, self._word_freq[key][\"rel\"]))\n",
    "        match.sort()\n",
    "        match = match[:5]\n",
    "        return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056645851917930416\n",
      "127   0.056645851917930416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 'be', 0.00936663693131133),\n",
       " (4, 'he', 0.0022301516503122213),\n",
       " (4, 'home', 0.0008920606601248885),\n",
       " (4, 'hurdle', 0.00044603033006244426),\n",
       " (4, 'number', 0.0013380909901873326)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "ca01 = brown.words(\"ca01\")\n",
    "\n",
    "ac = Autocorrect(ca01)\n",
    "\n",
    "print(ac._word_freq[\"the\"][\"cnt\"]/len(ca01))\n",
    "print(str(ac._word_freq[\"the\"][\"cnt\"]) + \"   \" + str(ac._word_freq[\"the\"][\"rel\"]))\n",
    "\n",
    "ac.checkWord(\"humble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('csc620')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a71d39d660cde086a1906713d7782789105334eb77ec37352255bdee7f037f90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
